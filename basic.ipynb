{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNGCIz1+tab978SZpq/8rHV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Bi9G40zy9Qyg","executionInfo":{"status":"ok","timestamp":1731764295712,"user_tz":-300,"elapsed":13412,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}}},"outputs":[],"source":["%%capture --no-stderr\n","!pip install -q langchain_google_genai langchain_core langchain_community tavily-python"]},{"cell_type":"code","source":["from google.colab import userdata\n","gemini = userdata.get('gemini')"],"metadata":{"id":"IlFzHBvq9bro","executionInfo":{"status":"ok","timestamp":1731765805579,"user_tz":-300,"elapsed":3350,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI"],"metadata":{"id":"bl6wp2_G_tec","executionInfo":{"status":"ok","timestamp":1731765809565,"user_tz":-300,"elapsed":755,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-1.5-flash\",\n","    api_key= gemini,\n","    temperature=0\n",")"],"metadata":{"id":"rtmShoq2_mOz","executionInfo":{"status":"ok","timestamp":1731765809566,"user_tz":-300,"elapsed":5,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["result  = llm.invoke(\"Who won 2024 US presidential ellection?\")\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJ2juUcv_pK2","executionInfo":{"status":"ok","timestamp":1731764384322,"user_tz":-300,"elapsed":82618,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}},"outputId":"48e1d681-365e-4c22-9930-0a74f197de02"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='The 2024 US presidential election has not yet happened.  The election will be held in November 2024.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-f44c9772-04f2-408a-860d-918de27f749a-0', usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["from langchain_core.messages import HumanMessage, AIMessage\n","\n","# Create a message\n","# Message list\n","messages = [\n","    HumanMessage(content=\"Hi\", name=\"Human Student\"),]\n","\n","# Invoke the model with a list of messages\n","llm.invoke(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-4niESBP2Iq","executionInfo":{"status":"ok","timestamp":1731765306211,"user_tz":-300,"elapsed":41617,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}},"outputId":"c4fd4a91-717e-4a47-8851-97ec1e7d2b58"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='Hi there! How can I help you today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-7923ed2b-6919-41b5-a0b1-46685f5119cf-0', usage_metadata={'input_tokens': 2, 'output_tokens': 11, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["messages = [\n","    HumanMessage(content=\"Hi\", name=\"Human Student\"),\n","    AIMessage(content='Hi! How can I help you today? \\n', name=\"AI Assistant\"),\n","    HumanMessage(content=\"What is LangChain?\", name=\"Human Student\"),]\n","\n","# Invoke the model with a list of messages\n","llm.invoke(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a6ZNZaQQjCy","executionInfo":{"status":"ok","timestamp":1731765935898,"user_tz":-300,"elapsed":40515,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}},"outputId":"4da3a5dc-15f1-48d5-dbfa-e128631e3b8e"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='LangChain is a framework for developing applications powered by language models.  It\\'s designed to make it easier to build applications that combine the capabilities of large language models (LLMs) with other sources of computation and knowledge.  Think of it as a toolbox filled with components and utilities that simplify the process of creating complex LLM-based systems.\\n\\nHere\\'s a breakdown of its key features and what makes it stand out:\\n\\n* **Modular Design:** LangChain is built with modularity in mind.  It breaks down the process of building LLM applications into distinct components, allowing developers to mix and match different parts to suit their specific needs.  This makes it highly flexible and adaptable.\\n\\n* **Abstraction of LLMs:** LangChain provides a consistent interface for interacting with various LLMs, regardless of their underlying provider (OpenAI, Hugging Face, etc.). This simplifies switching between different models and allows developers to easily experiment with different options.\\n\\n* **Memory:**  LangChain offers mechanisms for LLMs to retain information across multiple interactions. This is crucial for building conversational agents and applications that require context awareness.  This \"memory\" can be implemented in various ways, from simple in-memory storage to more sophisticated techniques like vector databases.\\n\\n* **Chains:**  This is a core concept in LangChain. Chains are sequences of calls to LLMs or other utilities, allowing you to create complex workflows.  For example, you might chain together an LLM that summarizes text, another that extracts key information, and a third that generates a report.\\n\\n* **Agents:**  LangChain provides tools for building agents that can autonomously decide which tools to use to answer a user\\'s query.  This allows for more sophisticated applications that can interact with external resources and perform actions beyond simply generating text.\\n\\n* **Indexes:**  LangChain helps you index and query your own data, allowing you to build applications that leverage your private documents or knowledge bases.  This is important for applications that need to access and process specific information.\\n\\nIn short, LangChain simplifies the development of LLM-powered applications by providing a structured and flexible framework, abstracting away many of the complexities involved in working with LLMs and other components.  It\\'s particularly useful for building applications that require more than just simple prompt-response interactions.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-423142f9-24d8-4379-aeea-6e972f19bd7f-0', usage_metadata={'input_tokens': 20, 'output_tokens': 475, 'total_tokens': 495, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["messages = [\n","    HumanMessage(content=\"Hi\", name=\"Human Student\"),\n","    AIMessage(content='Hi! How can I help you today? \\n', name=\"AI Assistant\"),\n","    HumanMessage(content=\"What is LangChain?\", name=\"Human Student\"),\n","    AIMessage(content='LangChain is a framework for developing applications powered by language models.', name=\"AI Assistant\"),\n","    HumanMessage(content=\"How can I learn\", name=\"Human Student\"),\n","    ]\n","\n","# Invoke the model with a list of messages\n","llm.invoke(messages)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UqLSltdABbl","executionInfo":{"status":"ok","timestamp":1731764461469,"user_tz":-300,"elapsed":51951,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}},"outputId":"2c90c61e-abaf-42eb-e2f5-71fd4531d8ea"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='There are several ways to learn LangChain, depending on your learning style and prior experience:\\n\\n**1. Official Documentation:** The best place to start is the official LangChain documentation.  It\\'s well-structured and provides comprehensive tutorials and examples.  Look for their \"Getting Started\" guides and work your way through the examples.\\n\\n**2. Tutorials and Blog Posts:** Many tutorials and blog posts are available online that cover various aspects of LangChain. Search for \"LangChain tutorial\" or \"LangChain examples\" on Google, YouTube, and Medium.  Look for tutorials that focus on specific use cases that interest you, such as building chatbots, question-answering systems, or document summarizers.\\n\\n**3. GitHub Repository:** Explore the LangChain GitHub repository.  You can find the source code, contribute to the project, and see how different components are implemented.  Reading the code can be a great way to deepen your understanding.\\n\\n**4. Example Projects:**  The LangChain documentation and GitHub repository contain many example projects.  Start by running and modifying these examples to understand how different parts of the framework work together.  Try changing parameters, adding new features, and experimenting with different language models.\\n\\n**5. Courses and Workshops:** While not as prevalent as for some other technologies, you might find online courses or workshops specifically on LangChain or related topics like LLM application development.  Check platforms like Coursera, Udemy, and edX.\\n\\n**6. Community:** Engage with the LangChain community.  Join their Discord server or other online forums to ask questions, share your progress, and learn from others.\\n\\n\\n**Learning Path Suggestion:**\\n\\n1. **Start with the official documentation\\'s \"Getting Started\" guide.** This will give you a foundational understanding of the core concepts and components.\\n2. **Work through a few simple tutorials.**  This will help you solidify your understanding and build confidence.\\n3. **Choose a specific project that interests you.** This will provide a focused learning experience and allow you to apply what you\\'ve learned.\\n4. **Explore the LangChain GitHub repository and examples.** This will deepen your understanding of the framework\\'s architecture and implementation.\\n5. **Engage with the community.**  This will help you learn from others and get support when you need it.\\n\\n\\nRemember to start small, focus on one concept at a time, and don\\'t be afraid to experiment.  LangChain is a powerful framework, but it\\'s also designed to be relatively easy to learn and use.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-aa3ecdea-fb58-49ff-bd9a-c520314eba3e-0', usage_metadata={'input_tokens': 39, 'output_tokens': 524, 'total_tokens': 563, 'input_token_details': {'cache_read': 0}})"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')\n","os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n","\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","tavily_search = TavilySearchResults(max_results=3)\n","search_docs = tavily_search.invoke(\"Who won 2024 US presidential ellection?\")"],"metadata":{"id":"GR3LTn3yOIff","executionInfo":{"status":"ok","timestamp":1731764753194,"user_tz":-300,"elapsed":10843,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["search_docs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXVHo5RWOTwb","executionInfo":{"status":"ok","timestamp":1731764769627,"user_tz":-300,"elapsed":537,"user":{"displayName":"Muhammad Atif","userId":"04349964476293178194"}},"outputId":"2b3d7675-6d3e-4645-92b6-fe2769ba528f"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'url': 'https://www.bbc.com/news/election/2024/us/results',\n","  'content': 'US Presidential Election Results 2024 - BBC News Close menu BBC News Kamala Harris of the Democrat party has 0 electoral college votes. Donald Trump of the Republican party has 0 electoral college votes. Kamala Harris of the Democrat party has 158,810 votes (38.4%) Donald Trump of the Republican party has 249,225 votes (60.2%) US presidential election results 2024 US election 2024 Voting in some states is particularly hard to predict, with polls showing they could be won by the Republicans or the Democratic party. The battleground states that could decide the 2024 presidential election are: Voters in 11 states will also elect a governor. US election polls: Who is ahead - Harris or Trump? US election 2024 About the BBC'},\n"," {'url': 'https://www.politico.com/2024-election/results/president/',\n","  'content': '2024 Election Results. 6 GOP flips. Harris. 226. Trump. 312. Nov. 9, 2024, 6:12 p.m. PST. Donald Trump is the next president of the United States. He racked up victories in all seven swing states'},\n"," {'url': 'https://www.usatoday.com/story/news/politics/elections/2024/11/05/election-2024-live-updates-results/75686839007/',\n","  'content': \"The result of all the tumult has been razor-thin polling margins in the Real Clear Politics average of national surveys, Trump led Harris by 0.1 percentage point, well within the margin of error for each of the surveys included. As Americans from coast to coast make their voices heard at the ballot box, keep up with the USA TODAY Network's live coverage of the 2024 presidential election and check back here for results. Election Day 2024 is here, and Harris and Trump are neck-and-neck in the polls. If you're still undecided between the Democratic and Republican nominees, check out USA TODAY's voter guide to see what Trump and Harris have said about major issues, in their own words.\"}]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"UWFzfP9eOUse"},"execution_count":null,"outputs":[]}]}